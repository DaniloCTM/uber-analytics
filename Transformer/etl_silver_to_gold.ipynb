{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed63491",
   "metadata": {},
   "source": [
    "# ETL: Silver ‚Üí Gold Layer\n",
    "\n",
    "**Objetivo:** Transformar dados do Silver em Data Warehouse (Gold) com Star Schema.\n",
    "\n",
    "**Processo:**\n",
    "1. Extrair dados de `silver.uber_silver`\n",
    "2. Popular 8 dimens√µes\n",
    "3. Popular tabela fato com m√©tricas e FKs\n",
    "4. Validar Data Warehouse\n",
    "\n",
    "**Schema:** dwh.dim_data, dim_tempo, dim_cliente, dim_veiculo, dim_status, dim_localizacao, dim_pagamento, dim_motivo_cancelamento ‚Üí fato_corridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0c6269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas importadas!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a031ae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conex√£o estabelecida!\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√£o PostgreSQL\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'uberdb',\n",
    "    'user': 'admin',\n",
    "    'password': 'uber.10'\n",
    "}\n",
    "\n",
    "def get_connection():\n",
    "    return psycopg2.connect(**DB_CONFIG)\n",
    "\n",
    "# Teste conex√£o\n",
    "try:\n",
    "    conn = get_connection()\n",
    "    print(\"‚úÖ Conex√£o estabelecida!\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a770d",
   "metadata": {},
   "source": [
    "## 0. PREPARA√á√ÉO: Criar Schema e Tabelas do DWH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c51767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Lendo arquivo gold_ddl.sql...\n",
      "üöÄ Executando DDL no PostgreSQL...\n",
      "‚úÖ Schema 'dwh' e todas as tabelas criadas com sucesso!\n",
      "\n",
      "üìä Tabelas criadas no schema 'dwh': 9\n",
      "   ‚Ä¢ dim_cliente\n",
      "   ‚Ä¢ dim_data\n",
      "   ‚Ä¢ dim_localizacao\n",
      "   ‚Ä¢ dim_motivo_cancelamento\n",
      "   ‚Ä¢ dim_pagamento\n",
      "   ‚Ä¢ dim_status\n",
      "   ‚Ä¢ dim_tempo\n",
      "   ‚Ä¢ dim_veiculo\n",
      "   ‚Ä¢ fato_corridas\n"
     ]
    }
   ],
   "source": [
    "# Executar DDL do Gold para criar schema e tabelas\n",
    "import os\n",
    "\n",
    "ddl_path = os.path.join('..', 'Data Layer', 'gold', 'gold_ddl.sql')\n",
    "\n",
    "print(\"üìÇ Lendo arquivo gold_ddl.sql...\")\n",
    "with open(ddl_path, 'r', encoding='utf-8') as f:\n",
    "    ddl_script = f.read()\n",
    "\n",
    "print(\"üöÄ Executando DDL no PostgreSQL...\")\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    cur.execute(ddl_script)\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Schema 'dwh' e todas as tabelas criadas com sucesso!\")\n",
    "    \n",
    "    # Verificar tabelas criadas\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'dwh'\n",
    "        ORDER BY table_name;\n",
    "    \"\"\")\n",
    "    tabelas = cur.fetchall()\n",
    "    print(f\"\\nüìä Tabelas criadas no schema 'dwh': {len(tabelas)}\")\n",
    "    for tabela in tabelas:\n",
    "        print(f\"   ‚Ä¢ {tabela[0]}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"‚ùå Erro ao executar DDL: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ed4e5",
   "metadata": {},
   "source": [
    "## 1. EXTRA√á√ÉO: Carregar Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a95c30b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\372627024.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_silver = pd.read_sql(query_silver, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros carregados: 97,765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booking_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>drop_location</th>\n",
       "      <th>booking_value</th>\n",
       "      <th>ride_distance</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>booking_status</th>\n",
       "      <th>reason_for_cancelling_by_customer</th>\n",
       "      <th>driver_cancellation_reason</th>\n",
       "      <th>incomplete_rides_reason</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>avg_vtat</th>\n",
       "      <th>avg_ctat</th>\n",
       "      <th>driver_ratings</th>\n",
       "      <th>customer_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNR4352144</td>\n",
       "      <td>CID8362794</td>\n",
       "      <td>Bike</td>\n",
       "      <td>Udyog Vihar</td>\n",
       "      <td>Ambience Mall</td>\n",
       "      <td>99.0</td>\n",
       "      <td>37.98</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>00:19:34</td>\n",
       "      <td>10.8</td>\n",
       "      <td>38.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNR9147645</td>\n",
       "      <td>CID8300238</td>\n",
       "      <td>Go Mini</td>\n",
       "      <td>Basai Dhankot</td>\n",
       "      <td>Madipur</td>\n",
       "      <td>114.0</td>\n",
       "      <td>39.29</td>\n",
       "      <td>Uber Wallet</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>01:35:18</td>\n",
       "      <td>8.5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNR8140858</td>\n",
       "      <td>CID9268400</td>\n",
       "      <td>Go Mini</td>\n",
       "      <td>Jhilmil</td>\n",
       "      <td>Welcome</td>\n",
       "      <td>735.0</td>\n",
       "      <td>39.39</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>01:53:01</td>\n",
       "      <td>8.1</td>\n",
       "      <td>42.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNR6073090</td>\n",
       "      <td>CID7393428</td>\n",
       "      <td>Go Mini</td>\n",
       "      <td>Sarojini Nagar</td>\n",
       "      <td>Madipur</td>\n",
       "      <td>918.0</td>\n",
       "      <td>44.21</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>03:59:29</td>\n",
       "      <td>2.9</td>\n",
       "      <td>33.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNR4082656</td>\n",
       "      <td>CID9685431</td>\n",
       "      <td>eBike</td>\n",
       "      <td>Panchsheel Park</td>\n",
       "      <td>Pragati Maidan</td>\n",
       "      <td>423.0</td>\n",
       "      <td>40.82</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>Reason Unknown</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>04:00:07</td>\n",
       "      <td>8.6</td>\n",
       "      <td>24.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booking_id customer_id vehicle_type  pickup_location   drop_location  \\\n",
       "0  CNR4352144  CID8362794         Bike      Udyog Vihar   Ambience Mall   \n",
       "1  CNR9147645  CID8300238      Go Mini    Basai Dhankot         Madipur   \n",
       "2  CNR8140858  CID9268400      Go Mini          Jhilmil         Welcome   \n",
       "3  CNR6073090  CID7393428      Go Mini   Sarojini Nagar         Madipur   \n",
       "4  CNR4082656  CID9685431        eBike  Panchsheel Park  Pragati Maidan   \n",
       "\n",
       "   booking_value  ride_distance payment_method booking_status  \\\n",
       "0           99.0          37.98           Cash      Completed   \n",
       "1          114.0          39.29    Uber Wallet      Completed   \n",
       "2          735.0          39.39            UPI      Completed   \n",
       "3          918.0          44.21           Cash      Completed   \n",
       "4          423.0          40.82           Cash      Completed   \n",
       "\n",
       "  reason_for_cancelling_by_customer driver_cancellation_reason  \\\n",
       "0                    Reason Unknown             Reason Unknown   \n",
       "1                    Reason Unknown             Reason Unknown   \n",
       "2                    Reason Unknown             Reason Unknown   \n",
       "3                    Reason Unknown             Reason Unknown   \n",
       "4                    Reason Unknown             Reason Unknown   \n",
       "\n",
       "  incomplete_rides_reason        date      time  avg_vtat  avg_ctat  \\\n",
       "0          Reason Unknown  2024-01-01  00:19:34      10.8      38.9   \n",
       "1          Reason Unknown  2024-01-01  01:35:18       8.5      15.1   \n",
       "2          Reason Unknown  2024-01-01  01:53:01       8.1      42.6   \n",
       "3          Reason Unknown  2024-01-01  03:59:29       2.9      33.8   \n",
       "4          Reason Unknown  2024-01-01  04:00:07       8.6      24.3   \n",
       "\n",
       "   driver_ratings  customer_rating  \n",
       "0             4.8              4.8  \n",
       "1             4.2              4.1  \n",
       "2             4.3              4.7  \n",
       "3             3.6              4.9  \n",
       "4             4.4              3.9  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_silver = \"\"\"\n",
    "SELECT booking_id, customer_id, vehicle_type, pickup_location, drop_location,\n",
    "       booking_value, ride_distance, payment_method, booking_status,\n",
    "       reason_for_cancelling_by_customer, driver_cancellation_reason, incomplete_rides_reason,\n",
    "       date, time, avg_vtat, avg_ctat, driver_ratings, customer_rating\n",
    "FROM silver.uber_silver\n",
    "ORDER BY date, time;\n",
    "\"\"\"\n",
    "\n",
    "conn = get_connection()\n",
    "df_silver = pd.read_sql(query_silver, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"üìä Registros carregados: {len(df_silver):,}\")\n",
    "df_silver.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb12ad",
   "metadata": {},
   "source": [
    "## 2. TRANSFORMA√á√ÉO: Criar Dimens√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95857a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_data: 730 registros (2024-01-01 00:00:00 a 2025-12-30 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Dim_Data\n",
    "df_silver['date'] = pd.to_datetime(df_silver['date'])\n",
    "min_date = df_silver['date'].min()\n",
    "max_date = df_silver['date'].max() + timedelta(days=365)\n",
    "date_range = pd.date_range(start=min_date, end=max_date, freq='D')\n",
    "\n",
    "dim_data = pd.DataFrame({\n",
    "    'data_completa': date_range,\n",
    "    'data_key': date_range.strftime('%Y%m%d').astype(int),\n",
    "    'ano': date_range.year,\n",
    "    'trimestre': date_range.quarter,\n",
    "    'mes': date_range.month,\n",
    "    'nome_mes': date_range.strftime('%B'),\n",
    "    'dia': date_range.day,\n",
    "    'dia_da_semana': date_range.dayofweek + 1,\n",
    "    'nome_dia_semana': date_range.strftime('%A'),\n",
    "    'fim_de_semana': date_range.dayofweek >= 5,\n",
    "    'dia_util': date_range.dayofweek < 5\n",
    "})\n",
    "\n",
    "print(f\"‚úÖ dim_data: {len(dim_data):,} registros ({dim_data['data_completa'].min()} a {dim_data['data_completa'].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a010d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_tempo: 1,440 registros\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Dim_Tempo\n",
    "times = pd.date_range('00:00', '23:59', freq='1min').time\n",
    "\n",
    "def classificar_periodo(hora):\n",
    "    if 0 <= hora < 6: return 'Madrugada'\n",
    "    elif 6 <= hora < 12: return 'Manh√£'\n",
    "    elif 12 <= hora < 18: return 'Tarde'\n",
    "    else: return 'Noite'\n",
    "\n",
    "def classificar_turno(hora):\n",
    "    if 8 <= hora < 18: return 'Comercial'\n",
    "    elif 18 <= hora < 23: return 'Noturno'\n",
    "    else: return 'Madrugada'\n",
    "\n",
    "dim_tempo = pd.DataFrame({\n",
    "    'tempo_key': [int(f\"{t.hour:02d}{t.minute:02d}\") for t in times],\n",
    "    'hora': [t.hour for t in times],\n",
    "    'minuto': [t.minute for t in times],\n",
    "    'periodo': [classificar_periodo(t.hour) for t in times],\n",
    "    'turno': [classificar_turno(t.hour) for t in times],\n",
    "    'hora_pico': [(7 <= t.hour <= 9) or (17 <= t.hour <= 19) for t in times]\n",
    "}).drop_duplicates(subset=['tempo_key'])\n",
    "\n",
    "print(f\"‚úÖ dim_tempo: {len(dim_tempo):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeeaba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_cliente: 97,268 registros\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Dim_Cliente\n",
    "dim_cliente = df_silver[['customer_id']].drop_duplicates().copy()\n",
    "dim_cliente['data_cadastro'] = df_silver.groupby('customer_id')['date'].min().values\n",
    "\n",
    "print(f\"‚úÖ dim_cliente: {len(dim_cliente):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44145fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_veiculo: 7 registros\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Dim_Veiculo\n",
    "dim_veiculo = df_silver[['vehicle_type']].drop_duplicates().copy()\n",
    "\n",
    "def categorizar_veiculo(vtype):\n",
    "    if pd.isna(vtype): return 'Desconhecido'\n",
    "    v_lower = str(vtype).lower()\n",
    "    if 'premium' in v_lower or 'luxury' in v_lower: return 'Premium'\n",
    "    elif 'bike' in v_lower or 'moto' in v_lower: return 'Bike'\n",
    "    else: return 'Econ√¥mico'\n",
    "\n",
    "dim_veiculo['categoria'] = dim_veiculo['vehicle_type'].apply(categorizar_veiculo)\n",
    "dim_veiculo['capacidade'] = None\n",
    "\n",
    "print(f\"‚úÖ dim_veiculo: {len(dim_veiculo)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da0c7dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_status: 2 registros\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.5 Dim_Status\n",
    "dim_status = df_silver[['booking_status']].drop_duplicates().copy()\n",
    "\n",
    "def categorizar_status(status):\n",
    "    if pd.isna(status): return 'Desconhecido', False\n",
    "    s_lower = str(status).lower()\n",
    "    if 'complete' in s_lower: return 'Completado', False\n",
    "    elif 'cancel' in s_lower: return 'Cancelado', False\n",
    "    elif 'incomplete' in s_lower: return 'Incompleto', False\n",
    "    else: return 'Ativo', True\n",
    "\n",
    "dim_status[['status_categoria', 'status_ativo']] = dim_status['booking_status'].apply(\n",
    "    lambda x: pd.Series(categorizar_status(x))\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ dim_status: {len(dim_status)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9feef754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_localizacao: 176 registros\n"
     ]
    }
   ],
   "source": [
    "# 2.6 Dim_Localizacao\n",
    "pickup_loc = df_silver[['pickup_location']].rename(columns={'pickup_location': 'local_nome'})\n",
    "drop_loc = df_silver[['drop_location']].rename(columns={'drop_location': 'local_nome'})\n",
    "dim_localizacao = pd.concat([pickup_loc, drop_loc]).drop_duplicates()\n",
    "dim_localizacao['regiao'] = None\n",
    "dim_localizacao['zona'] = None\n",
    "\n",
    "print(f\"‚úÖ dim_localizacao: {len(dim_localizacao):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a41cf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_pagamento: 5 registros\n"
     ]
    }
   ],
   "source": [
    "# 2.7 Dim_Pagamento\n",
    "dim_pagamento = df_silver[['payment_method']].drop_duplicates().copy()\n",
    "\n",
    "def classificar_pagamento(method):\n",
    "    if pd.isna(method): return 'Desconhecido'\n",
    "    m_lower = str(method).lower()\n",
    "    return 'Dinheiro' if 'cash' in m_lower or 'dinheiro' in m_lower else 'Digital'\n",
    "\n",
    "dim_pagamento['tipo_pagamento'] = dim_pagamento['payment_method'].apply(classificar_pagamento)\n",
    "\n",
    "print(f\"‚úÖ dim_pagamento: {len(dim_pagamento)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6890d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_motivo_cancelamento: 4 registros\n"
     ]
    }
   ],
   "source": [
    "# 2.8 Dim_Motivo_Cancelamento\n",
    "dim_motivo = df_silver[[\n",
    "    'reason_for_cancelling_by_customer', 'driver_cancellation_reason', 'incomplete_rides_reason'\n",
    "]].drop_duplicates().copy()\n",
    "\n",
    "def criar_hash_motivo(row):\n",
    "    motivo_str = f\"{row['reason_for_cancelling_by_customer']}|{row['driver_cancellation_reason']}|{row['incomplete_rides_reason']}\"\n",
    "    return hashlib.md5(motivo_str.encode()).hexdigest()\n",
    "\n",
    "dim_motivo['motivo_hash'] = dim_motivo.apply(criar_hash_motivo, axis=1)\n",
    "\n",
    "print(f\"‚úÖ dim_motivo_cancelamento: {len(dim_motivo):,} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdda0f5",
   "metadata": {},
   "source": [
    "## 3. CARGA: Inserir Dimens√µes no DWH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb124806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_data inserida: 730 registros\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Inserir dim_data\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.dim_data CASCADE;\")\n",
    "\n",
    "data_values = [\n",
    "    (int(row['data_key']), row['data_completa'].date(), int(row['ano']), int(row['trimestre']),\n",
    "     int(row['mes']), row['nome_mes'], int(row['dia']), int(row['dia_da_semana']),\n",
    "     row['nome_dia_semana'], bool(row['fim_de_semana']), bool(row['dia_util']))\n",
    "    for _, row in dim_data.iterrows()\n",
    "]\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO dwh.dim_data (data_key, data_completa, ano, trimestre, mes, nome_mes, \n",
    "                          dia, dia_da_semana, nome_dia_semana, fim_de_semana, dia_util)\n",
    "VALUES %s\n",
    "\"\"\"\n",
    "execute_values(cur, insert_query, data_values, page_size=1000)\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.dim_data;\")\n",
    "print(f\"‚úÖ dim_data inserida: {cur.fetchone()[0]:,} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "233d4168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_tempo inserida: 1,440 registros\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Inserir dim_tempo\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.dim_tempo CASCADE;\")\n",
    "\n",
    "tempo_values = [(int(row['tempo_key']), int(row['hora']), int(row['minuto']),\n",
    "                 row['periodo'], row['turno'], bool(row['hora_pico']))\n",
    "                for _, row in dim_tempo.iterrows()]\n",
    "\n",
    "execute_values(cur, \"\"\"\n",
    "INSERT INTO dwh.dim_tempo (tempo_key, hora, minuto, periodo, turno, hora_pico)\n",
    "VALUES %s\n",
    "\"\"\", tempo_values, page_size=1000)\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.dim_tempo;\")\n",
    "print(f\"‚úÖ dim_tempo inserida: {cur.fetchone()[0]:,} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4ef3c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_cliente inserida: 97,268 registros\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Inserir dim_cliente\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.dim_cliente CASCADE;\")\n",
    "\n",
    "for _, row in dim_cliente.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_cliente (customer_id, data_cadastro)\n",
    "    VALUES (%s, %s);\n",
    "    \"\"\", (row['customer_id'], row['data_cadastro'].date()))\n",
    "\n",
    "conn.commit()\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.dim_cliente;\")\n",
    "print(f\"‚úÖ dim_cliente inserida: {cur.fetchone()[0]:,} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af080630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_veiculo inserida: 7 registros\n"
     ]
    }
   ],
   "source": [
    "# 3.4 Inserir dim_veiculo\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.dim_veiculo CASCADE;\")\n",
    "\n",
    "for _, row in dim_veiculo.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_veiculo (vehicle_type, categoria, capacidade)\n",
    "    VALUES (%s, %s, %s);\n",
    "    \"\"\", (row['vehicle_type'], row['categoria'], row['capacidade']))\n",
    "\n",
    "conn.commit()\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.dim_veiculo;\")\n",
    "print(f\"‚úÖ dim_veiculo inserida: {cur.fetchone()[0]} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86b8953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_status inserida: 2 registros\n"
     ]
    }
   ],
   "source": [
    "# 3.5 Inserir dim_status\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.dim_status CASCADE;\")\n",
    "\n",
    "for _, row in dim_status.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_status (booking_status, status_categoria, status_ativo)\n",
    "    VALUES (%s, %s, %s);\n",
    "    \"\"\", (row['booking_status'], row['status_categoria'], row['status_ativo']))\n",
    "\n",
    "conn.commit()\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.dim_status;\")\n",
    "print(f\"‚úÖ dim_status inserida: {cur.fetchone()[0]} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "656247b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_localizacao inserida: 176 registros\n"
     ]
    }
   ],
   "source": [
    "# 3.6 Inserir dim_localizacao\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.dim_localizacao CASCADE;\")\n",
    "\n",
    "for _, row in dim_localizacao.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_localizacao (local_nome, regiao, zona)\n",
    "    VALUES (%s, %s, %s);\n",
    "    \"\"\", (row['local_nome'], row['regiao'], row['zona']))\n",
    "\n",
    "conn.commit()\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.dim_localizacao;\")\n",
    "print(f\"‚úÖ dim_localizacao inserida: {cur.fetchone()[0]:,} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8def0181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_pagamento inserida: 5 registros\n"
     ]
    }
   ],
   "source": [
    "# 3.7 Inserir dim_pagamento\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.dim_pagamento CASCADE;\")\n",
    "\n",
    "for _, row in dim_pagamento.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_pagamento (payment_method, tipo_pagamento)\n",
    "    VALUES (%s, %s);\n",
    "    \"\"\", (row['payment_method'], row['tipo_pagamento']))\n",
    "\n",
    "conn.commit()\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.dim_pagamento;\")\n",
    "print(f\"‚úÖ dim_pagamento inserida: {cur.fetchone()[0]} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bffa9db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_motivo_cancelamento inserida: 4 registros\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.8 Inserir dim_motivo_cancelamento\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.dim_motivo_cancelamento CASCADE;\")\n",
    "\n",
    "for _, row in dim_motivo.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_motivo_cancelamento \n",
    "    (reason_cancel_customer, driver_cancellation_reason, incomplete_rides_reason, motivo_hash)\n",
    "    VALUES (%s, %s, %s, %s);\n",
    "    \"\"\", (row['reason_for_cancelling_by_customer'], row['driver_cancellation_reason'],\n",
    "          row['incomplete_rides_reason'], row['motivo_hash']))\n",
    "\n",
    "conn.commit()\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.dim_motivo_cancelamento;\")\n",
    "print(f\"‚úÖ dim_motivo_cancelamento inserida: {cur.fetchone()[0]:,} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f490fe",
   "metadata": {},
   "source": [
    "## 4. PREPARAR FATO: Lookups e Transforma√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abd2ce6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Lookups carregados (Cliente: 97,268, Localiza√ß√µes: 176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\163234229.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  lookup_cliente = pd.read_sql(\"SELECT cliente_key, customer_id FROM dwh.dim_cliente\", conn)\n",
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\163234229.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  lookup_veiculo = pd.read_sql(\"SELECT veiculo_key, vehicle_type FROM dwh.dim_veiculo\", conn)\n",
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\163234229.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  lookup_status = pd.read_sql(\"SELECT status_key, booking_status FROM dwh.dim_status\", conn)\n",
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\163234229.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  lookup_pagamento = pd.read_sql(\"SELECT pagamento_key, payment_method FROM dwh.dim_pagamento\", conn)\n",
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\163234229.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  lookup_localizacao = pd.read_sql(\"SELECT local_key, local_nome FROM dwh.dim_localizacao\", conn)\n",
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\163234229.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  lookup_motivo = pd.read_sql(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Carregar lookups das dimens√µes\n",
    "conn = get_connection()\n",
    "lookup_cliente = pd.read_sql(\"SELECT cliente_key, customer_id FROM dwh.dim_cliente\", conn)\n",
    "lookup_veiculo = pd.read_sql(\"SELECT veiculo_key, vehicle_type FROM dwh.dim_veiculo\", conn)\n",
    "lookup_status = pd.read_sql(\"SELECT status_key, booking_status FROM dwh.dim_status\", conn)\n",
    "lookup_pagamento = pd.read_sql(\"SELECT pagamento_key, payment_method FROM dwh.dim_pagamento\", conn)\n",
    "lookup_localizacao = pd.read_sql(\"SELECT local_key, local_nome FROM dwh.dim_localizacao\", conn)\n",
    "lookup_motivo = pd.read_sql(\"\"\"\n",
    "    SELECT motivo_key, reason_cancel_customer, driver_cancellation_reason, incomplete_rides_reason \n",
    "    FROM dwh.dim_motivo_cancelamento\n",
    "\"\"\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Renomear coluna do lookup para fazer merge correto\n",
    "lookup_motivo = lookup_motivo.rename(columns={'reason_cancel_customer': 'reason_for_cancelling_by_customer'})\n",
    "\n",
    "print(f\"‚úÖ Lookups carregados (Cliente: {len(lookup_cliente):,}, Localiza√ß√µes: {len(lookup_localizacao):,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66b49872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fato preparada: 97,765 registros\n",
      "   Completas: 97,765\n",
      "   Canceladas: 0\n"
     ]
    }
   ],
   "source": [
    "# Preparar tabela fato\n",
    "df_fato = df_silver.copy()\n",
    "\n",
    "# Criar chaves\n",
    "df_fato['data_key'] = pd.to_datetime(df_fato['date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "def time_to_key(time_str):\n",
    "    if pd.isna(time_str) or time_str == '': return None\n",
    "    try:\n",
    "        time_obj = pd.to_datetime(time_str, format='%H:%M:%S').time()\n",
    "        return int(f\"{time_obj.hour:02d}{time_obj.minute:02d}\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_fato['tempo_key'] = df_fato['time'].apply(time_to_key)\n",
    "\n",
    "# Merge com dimens√µes\n",
    "df_fato = df_fato.merge(lookup_cliente, on='customer_id', how='left')\n",
    "df_fato = df_fato.merge(lookup_veiculo, on='vehicle_type', how='left')\n",
    "df_fato = df_fato.merge(lookup_status, on='booking_status', how='left')\n",
    "df_fato = df_fato.merge(lookup_pagamento, on='payment_method', how='left')\n",
    "df_fato = df_fato.merge(\n",
    "    lookup_localizacao.rename(columns={'local_key': 'pickup_local_key', 'local_nome': 'pickup_location'}),\n",
    "    on='pickup_location', how='left'\n",
    ")\n",
    "df_fato = df_fato.merge(\n",
    "    lookup_localizacao.rename(columns={'local_key': 'drop_local_key', 'local_nome': 'drop_location'}),\n",
    "    on='drop_location', how='left'\n",
    ")\n",
    "df_fato = df_fato.merge(\n",
    "    lookup_motivo,\n",
    "    on=['reason_for_cancelling_by_customer', 'driver_cancellation_reason', 'incomplete_rides_reason'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calcular m√©tricas derivadas\n",
    "df_fato['valor_por_km'] = df_fato.apply(\n",
    "    lambda x: round(x['booking_value'] / x['ride_distance'], 2) \n",
    "    if pd.notna(x['ride_distance']) and x['ride_distance'] > 0 else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Flags booleanas\n",
    "df_fato['corrida_completa'] = df_fato['booking_status'].str.lower().str.contains('complete', na=False)\n",
    "df_fato['corrida_cancelada'] = df_fato['booking_status'].str.lower().str.contains('cancel', na=False)\n",
    "df_fato['corrida_incompleta'] = df_fato['booking_status'].str.lower().str.contains('incomplete', na=False)\n",
    "\n",
    "print(f\"‚úÖ Fato preparada: {len(df_fato):,} registros\")\n",
    "print(f\"   Completas: {df_fato['corrida_completa'].sum():,}\")\n",
    "print(f\"   Canceladas: {df_fato['corrida_cancelada'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79188bc",
   "metadata": {},
   "source": [
    "## 5. CARGA: Inserir Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3bdbb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Inserindo 97,765 registros em 98 batches...\n",
      "   Batch 10/98\n",
      "   Batch 10/98\n",
      "   Batch 20/98\n",
      "   Batch 20/98\n",
      "   Batch 30/98\n",
      "   Batch 30/98\n",
      "   Batch 40/98\n",
      "   Batch 40/98\n",
      "   Batch 50/98\n",
      "   Batch 50/98\n",
      "   Batch 60/98\n",
      "   Batch 60/98\n",
      "   Batch 70/98\n",
      "   Batch 70/98\n",
      "   Batch 80/98\n",
      "   Batch 80/98\n",
      "   Batch 90/98\n",
      "   Batch 90/98\n",
      "\n",
      "‚úÖ fato_corridas inserida: 97,765 registros\n",
      "\n",
      "‚úÖ fato_corridas inserida: 97,765 registros\n"
     ]
    }
   ],
   "source": [
    "# Selecionar colunas para inser√ß√£o\n",
    "fato_columns = [\n",
    "    'booking_id', 'data_key', 'tempo_key', 'cliente_key', 'veiculo_key',\n",
    "    'status_key', 'pagamento_key', 'pickup_local_key', 'drop_local_key', 'motivo_key',\n",
    "    'booking_value', 'ride_distance', 'avg_vtat', 'avg_ctat', \n",
    "    'driver_ratings', 'customer_rating', 'valor_por_km',\n",
    "    'corrida_completa', 'corrida_cancelada', 'corrida_incompleta'\n",
    "]\n",
    "\n",
    "df_fato_insert = df_fato[fato_columns].where(pd.notnull(df_fato[fato_columns]), None)\n",
    "fato_values = [tuple(row) for row in df_fato_insert.values]\n",
    "\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"TRUNCATE TABLE dwh.fato_corridas;\")\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO dwh.fato_corridas (\n",
    "    corrida_key, data_key, tempo_key, cliente_key, veiculo_key,\n",
    "    status_key, pagamento_key, pickup_local_key, drop_local_key, motivo_key,\n",
    "    booking_value, ride_distance, avg_vtat, avg_ctat,\n",
    "    driver_ratings, customer_rating, valor_por_km,\n",
    "    corrida_completa, corrida_cancelada, corrida_incompleta\n",
    ")\n",
    "VALUES %s\n",
    "ON CONFLICT (corrida_key) DO NOTHING;\n",
    "\"\"\"\n",
    "\n",
    "# Inserir em batches\n",
    "batch_size = 1000\n",
    "total_batches = (len(fato_values) + batch_size - 1) // batch_size\n",
    "print(f\"üöÄ Inserindo {len(fato_values):,} registros em {total_batches} batches...\")\n",
    "\n",
    "for i in range(0, len(fato_values), batch_size):\n",
    "    batch = fato_values[i:i+batch_size]\n",
    "    execute_values(cur, insert_query, batch, page_size=batch_size)\n",
    "    if (i // batch_size + 1) % 10 == 0:\n",
    "        print(f\"   Batch {i // batch_size + 1}/{total_batches}\")\n",
    "\n",
    "conn.commit()\n",
    "cur.execute(\"SELECT COUNT(*) FROM dwh.fato_corridas;\")\n",
    "print(f\"\\n‚úÖ fato_corridas inserida: {cur.fetchone()[0]:,} registros\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0403cd66",
   "metadata": {},
   "source": [
    "## 6. VALIDA√á√ÉO do Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82ac36bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä VALIDA√á√ÉO DO DATA WAREHOUSE\n",
      "============================================================\n",
      "Total Corridas..........................          97,765\n",
      "Corridas Completas......................          97,765\n",
      "Corridas Canceladas.....................               0\n",
      "Total Clientes..........................          97,268\n",
      "Total Localiza√ß√µes......................             176\n",
      "Receita Total...........................   45,100,932.00\n",
      "Dist√¢ncia Total (km)....................    2,408,269.23\n",
      "M√©dia Rating Motorista..................            4.23\n",
      "M√©dia Rating Cliente....................            4.40\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\431160650.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn).iloc[0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Verificar integridade\n",
    "conn = get_connection()\n",
    "validation_queries = {\n",
    "    'Total Corridas': \"SELECT COUNT(*) FROM dwh.fato_corridas\",\n",
    "    'Corridas Completas': \"SELECT COUNT(*) FROM dwh.fato_corridas WHERE corrida_completa = TRUE\",\n",
    "    'Corridas Canceladas': \"SELECT COUNT(*) FROM dwh.fato_corridas WHERE corrida_cancelada = TRUE\",\n",
    "    'Total Clientes': \"SELECT COUNT(*) FROM dwh.dim_cliente\",\n",
    "    'Total Localiza√ß√µes': \"SELECT COUNT(*) FROM dwh.dim_localizacao\",\n",
    "    'Receita Total': \"SELECT SUM(booking_value) FROM dwh.fato_corridas\",\n",
    "    'Dist√¢ncia Total (km)': \"SELECT SUM(ride_distance) FROM dwh.fato_corridas\",\n",
    "    'M√©dia Rating Motorista': \"SELECT AVG(driver_ratings) FROM dwh.fato_corridas WHERE driver_ratings IS NOT NULL\",\n",
    "    'M√©dia Rating Cliente': \"SELECT AVG(customer_rating) FROM dwh.fato_corridas WHERE customer_rating IS NOT NULL\"\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä VALIDA√á√ÉO DO DATA WAREHOUSE\")\n",
    "print(\"=\"*60)\n",
    "for label, query in validation_queries.items():\n",
    "    result = pd.read_sql(query, conn).iloc[0, 0]\n",
    "    if isinstance(result, (int, np.integer)):\n",
    "        print(f\"{label:.<40} {result:>15,}\")\n",
    "    elif isinstance(result, (float, np.floating)):\n",
    "        print(f\"{label:.<40} {result:>15,.2f}\")\n",
    "print(\"=\"*60)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73625f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcos.marinho\\AppData\\Local\\Temp\\ipykernel_28648\\2927494190.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_top_rotas = pd.read_sql(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ TOP 10 ROTAS MAIS RENT√ÅVEIS:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origem</th>\n",
       "      <th>destino</th>\n",
       "      <th>total_corridas</th>\n",
       "      <th>receita_total</th>\n",
       "      <th>ticket_medio</th>\n",
       "      <th>distancia_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kirti Nagar</td>\n",
       "      <td>Yamuna Bank</td>\n",
       "      <td>8</td>\n",
       "      <td>6921.0</td>\n",
       "      <td>865.125000</td>\n",
       "      <td>27.801250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paharganj</td>\n",
       "      <td>Sarojini Nagar</td>\n",
       "      <td>11</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>618.181818</td>\n",
       "      <td>22.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ghitorni</td>\n",
       "      <td>Mandi House</td>\n",
       "      <td>10</td>\n",
       "      <td>6517.0</td>\n",
       "      <td>651.700000</td>\n",
       "      <td>24.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vaishali</td>\n",
       "      <td>IIT Delhi</td>\n",
       "      <td>11</td>\n",
       "      <td>6450.0</td>\n",
       "      <td>586.363636</td>\n",
       "      <td>22.357273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ardee City</td>\n",
       "      <td>Nirman Vihar</td>\n",
       "      <td>10</td>\n",
       "      <td>6433.0</td>\n",
       "      <td>643.300000</td>\n",
       "      <td>20.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jahangirpuri</td>\n",
       "      <td>Ashram</td>\n",
       "      <td>8</td>\n",
       "      <td>6391.0</td>\n",
       "      <td>798.875000</td>\n",
       "      <td>23.961250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rithala</td>\n",
       "      <td>Udyog Vihar Phase 4</td>\n",
       "      <td>11</td>\n",
       "      <td>6325.0</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>18.859091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rithala</td>\n",
       "      <td>Basai Dhankot</td>\n",
       "      <td>10</td>\n",
       "      <td>6278.0</td>\n",
       "      <td>627.800000</td>\n",
       "      <td>20.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mehrauli</td>\n",
       "      <td>Netaji Subhash Place</td>\n",
       "      <td>9</td>\n",
       "      <td>6250.0</td>\n",
       "      <td>694.444444</td>\n",
       "      <td>17.041111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rohini West</td>\n",
       "      <td>Sohna Road</td>\n",
       "      <td>13</td>\n",
       "      <td>6204.0</td>\n",
       "      <td>477.230769</td>\n",
       "      <td>29.408462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         origem               destino  total_corridas  receita_total  \\\n",
       "0   Kirti Nagar           Yamuna Bank               8         6921.0   \n",
       "1     Paharganj        Sarojini Nagar              11         6800.0   \n",
       "2      Ghitorni           Mandi House              10         6517.0   \n",
       "3      Vaishali             IIT Delhi              11         6450.0   \n",
       "4    Ardee City          Nirman Vihar              10         6433.0   \n",
       "5  Jahangirpuri                Ashram               8         6391.0   \n",
       "6       Rithala   Udyog Vihar Phase 4              11         6325.0   \n",
       "7       Rithala         Basai Dhankot              10         6278.0   \n",
       "8      Mehrauli  Netaji Subhash Place               9         6250.0   \n",
       "9   Rohini West            Sohna Road              13         6204.0   \n",
       "\n",
       "   ticket_medio  distancia_media  \n",
       "0    865.125000        27.801250  \n",
       "1    618.181818        22.560000  \n",
       "2    651.700000        24.223000  \n",
       "3    586.363636        22.357273  \n",
       "4    643.300000        20.874000  \n",
       "5    798.875000        23.961250  \n",
       "6    575.000000        18.859091  \n",
       "7    627.800000        20.076000  \n",
       "8    694.444444        17.041111  \n",
       "9    477.230769        29.408462  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query anal√≠tica: Top 10 rotas por receita\n",
    "conn = get_connection()\n",
    "df_top_rotas = pd.read_sql(\"\"\"\n",
    "SELECT pickup.local_nome AS origem, drop.local_nome AS destino,\n",
    "       COUNT(*) AS total_corridas,\n",
    "       SUM(f.booking_value) AS receita_total,\n",
    "       AVG(f.booking_value) AS ticket_medio,\n",
    "       AVG(f.ride_distance) AS distancia_media\n",
    "FROM dwh.fato_corridas f\n",
    "JOIN dwh.dim_localizacao pickup ON f.pickup_local_key = pickup.local_key\n",
    "JOIN dwh.dim_localizacao drop ON f.drop_local_key = drop.local_key\n",
    "WHERE f.corrida_completa = TRUE\n",
    "GROUP BY pickup.local_nome, drop.local_nome\n",
    "ORDER BY receita_total DESC\n",
    "LIMIT 10;\n",
    "\"\"\", conn)\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nüèÜ TOP 10 ROTAS MAIS RENT√ÅVEIS:\\n\")\n",
    "df_top_rotas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63199c07",
   "metadata": {},
   "source": [
    "## 7. SUM√ÅRIO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e319510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "               üéØ ETL SILVER ‚Üí GOLD CONCLU√çDO! üéØ\n",
      "======================================================================\n",
      "\n",
      "üìä RESUMO DA CARGA:\n",
      "----------------------------------------------------------------------\n",
      "Dimens√£o Data.....................................             730 registros\n",
      "Dimens√£o Tempo....................................           1,440 registros\n",
      "Dimens√£o Cliente..................................          97,268 registros\n",
      "Dimens√£o Ve√≠culo..................................               7 registros\n",
      "Dimens√£o Status...................................               2 registros\n",
      "Dimens√£o Localiza√ß√£o..............................             176 registros\n",
      "Dimens√£o Pagamento................................               5 registros\n",
      "Dimens√£o Motivo...................................               4 registros\n",
      "üåü FATO CORRIDAS...................................          97,765 registros\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Data Warehouse pronto para an√°lises!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 15 + \"üéØ ETL SILVER ‚Üí GOLD CONCLU√çDO! üéØ\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìä RESUMO DA CARGA:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "tabelas = [\n",
    "    ('dwh.dim_data', 'Dimens√£o Data'),\n",
    "    ('dwh.dim_tempo', 'Dimens√£o Tempo'),\n",
    "    ('dwh.dim_cliente', 'Dimens√£o Cliente'),\n",
    "    ('dwh.dim_veiculo', 'Dimens√£o Ve√≠culo'),\n",
    "    ('dwh.dim_status', 'Dimens√£o Status'),\n",
    "    ('dwh.dim_localizacao', 'Dimens√£o Localiza√ß√£o'),\n",
    "    ('dwh.dim_pagamento', 'Dimens√£o Pagamento'),\n",
    "    ('dwh.dim_motivo_cancelamento', 'Dimens√£o Motivo'),\n",
    "    ('dwh.fato_corridas', 'üåü FATO CORRIDAS')\n",
    "]\n",
    "\n",
    "for tabela, descricao in tabelas:\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {tabela};\")\n",
    "    count = cur.fetchone()[0]\n",
    "    print(f\"{descricao:.<50} {count:>15,} registros\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Data Warehouse pronto para an√°lises!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
